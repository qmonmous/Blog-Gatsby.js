---
layout: post
title: üá´üá∑ Introduction au Natural Language Preprocessing - NLPXP (Part. 1) / En cours d'√©criture
author: Quentin Monmousseau
tags: [Data Sc. & A.I.]
image: images/header-articles.1.png
date: 2019-05-20T23:46:37.121Z
draft: false
---

*Dans cet article, nous d√©couvrons les fondamentaux du Natural Language Processing en se concentrant sur le preprocessing des donn√©es.*

---

**‚Äî Sommaire**

**[I. Introduction](#one)**  
‚Ä¢ [A. Le Natural Language Processing](#one-a)  
‚Ä¢ [B. Du texte √† la matrice : le bag-of-words](#one-b)  

**[II. Preprocessing](#two)**  
‚Ä¢ [A. R√©cup√©ration du corpus](#two-a)  
‚Ä¢ [B. La tokenization](#two-b)  
‚Ä¢ [C. Reformatage (Regex, lowercase)](#two-c)  
‚Ä¢ [D. Suppression des stop-words](#two-d)  
‚Ä¢ [E. Les mots les plus fr√©quents](#two-e)  
‚Ä¢ [F. La lemmatisation](#two-f)  
‚Ä¢ [G. Le stemming](#two-g)

---

<a id="one"></a>
## I. Introduction

<a id="one-a"></a>
### A. Le Natural Language Processing

Le *Natural Language Processing* (ou *NLP*) est un ensemble de m√©thodes informatiques permettant de <mark>comprendre ou d'analyser le langage humain</mark>. On parle de *corpus* pour d√©signer l'ensemble des documents analys√©s.

On peut avoir une approche purement statistique (on parle alors de lexicom√©trie) en √©tudiant des donn√©es telles que les occurrences des mots par exemple.  
Plus largement, le NLP va permettre de mod√©liser des motifs dans le texte en s'int√©ressant √† la co-occurence de certains mots par exemple. Ainsi, si il est extr√™mement difficile de trouver des r√®gles tout √† fait g√©n√©rales en NLP, le Machine Learning va permettre de les d√©couvrir et de les appliquer aux corpus suivants.

![](images/whatisnlp.jpg)
###### Looks fascinating, right?

Voici, entre autres, quelques sujets sur lesquels travailler avec du NLP :
- l‚Äôanalyse de sentiments,
- la mod√©lisation de th√©matiques,
- la traduction automatique...

<a id="one-a"></a>
### B. Du texte √† la matrice : le *bag-of-words*

Comme introduit dans mon article sur le Machine Learning, il est n√©cessaire de repr√©senter nos donn√©es sous forme de matrices pour - *in fine* - leur appliquer des mod√®les pr√©dictifs.
Prenons le corpus suivant : <code>"Je suis un homme. Un homme souvent paradoxal."</code>.  
Il est possible de repr√©senter ce corpus sous forme de vecteur. A chaque fois qu‚Äôun nouveau mot appara√Æt, il est ajout√© au vecteur :
<code>[je suis un homme souvent paradoxal]</code>

Pour d√©crire une phrase, on va ensuite attribuer 1 si le mot est pr√©sent, 0 sinon.
<code>"Un homme souvent paradoxal"</code> devient <code>[0 0 1 1 1 1]</code>.

On forme ce qu'on appelle des *bag-of-words* !

- **Le *bag-of-words*** : Pour que chaque occurence de mots ne viennent pas agrandir le vecteur, nous les regroupons en les ajoutant √† leur premi√®re apparition. Cela va former un vecteur dont la longueur est <mark>l'ensemble du vocabulaire</mark> (c'est-√†-dire des mots diff√©rents) <mark>dans l'ensemble des documents du corpus</mark>. Chaque document pourra ainsi √™tre d√©crit par ce m√™me vecteur [a b c ...] avec a, b, c, ... le nombre d'occurences ‚Äì dans le document ‚Äì du mot repr√©sent√©.

Par ailleurs, forcer le vecteur √† attribuer une position fixe √† chaque mot commence √† r√©pondre √† une probl√©matique inh√©rente au NLP. Plus le corpus est grand, plus le vecteur va contenir de mots et donc devenir co√ªteux d‚Äôun point de vue calcul machine. Il existe donc des m√©thodes permettant, par exemple, de regrouper les mots sous la forme de leur radical : <code>[d√©couper, coupant, couperaient]</code> deviennent <code>[coupe]</code>. Cela permet de limiter le temps de calcul tout en conservant (g√©n√©ralement) le sens des mots. Mais passons √† la pratique.

---

<a id="two"></a>
## II. Preprocessing

Dans cet article, j'ai choisi de travailler avec la librairie *NLTK*. Il en existe d'autres telles que les librairies *spaCy* et *Gensim* qui permettent elles aussi de r√©aliser la plupart des √©tapes qui vont suivre.

<a id="two-a"></a>
### A. R√©cup√©ration du corpus

La premi√®re √©tape consiste √† r√©cup√©rer le corpus sur lequel on souhaite travailler. Pour se faire, il existe diff√©rentes m√©thodes qui ne seront pas d√©crites en d√©tail dans cet article.  
On pourrait par exemple r√©cup√©rer des fichiers de donn√©es sur des plateformes opendata (comme Kaggle) ou scraper des pages web pour en extraire le contenu ([voir mon article sur le scraping](https://quentin-monmousseau.netlify.com/WMXP/part-1/)).  
Pour avoir une premi√®re intuition des fonctions que nous allons utiliser, prenons les phrases suivantes en guise de corpus : 

```python
# Import de NLTK, librairie phare du NLP
import nltk
nltk.download('punkt')

# G√©n√©ration du corpus
corpus = "Ceci est une introduction √† l‚Äôanalyse textuelle.¬†Do$nt l'analyse pour‚Äôrait po$$ser probl√®me." 
```

On va maintenant se rapprocher de la repr√©sentation vectorielle attendue. Pour se faire, on peut *tokenizer* notre corpus.

<a id="two-b"></a>
### B. **La *tokenization*** 

- **La *tokenization*** : permet le d√©coupage en mots des diff√©rents documents qui constituent le corpus.

```python
# Tokenization en vecteur de mots
clean_corpus = nltk.word_tokenize(corpus)
```

Il est maintenant possible de nettoyer le texte pour le pr√©parer √† l‚Äôanalyse.  
Il s'agit de **normaliser** le vecteur de mots dans le but de supprimer des d√©tails inutiles au dictionnaire qu‚Äôon souhaite construire (ponctuation, caract√®res sp√©ciaux, conjugaison, mots ayant trop de poids dans le cadre d‚Äôun mod√®le pr√©dictif de th√©matiques‚Ä¶). Pour cela, voici les m√©thodes les plus commun√©ment appliquer.

<a id="two-c"></a>
### C. Reformatage (Regex, lowercase)

- **Les *Regex*** : (ou expressions r√©guli√®res) permettent de filtrer les cha√Ænes de caract√®res pour se d√©barasser de certains caract√®res inutiles comme des √©l√©ments de ponctuation.

```python
# Tokenization avec application d‚Äôune regex pour se d√©barrasser des caract√®res inutiles
tokenizer = nltk.RegexpTokenizer(r'\w+')
clean_corpus = tokenizer.tokenize(corpus)
```

On peut maintenant compter le nombre de mots qui composent le corpus.

```python
# Longueur du corpus (mots)
print(len(clean_corpus))
```

- **Le *lowercase*** : consiste √† passer toutes les lettres des mots en minuscules. Ceci permet d'√©viter qu'un m√™me mot soit pr√©sent deux fois dans le vecteur (ex : <code>"Je"</code> et <code>"je"</code>).

```python
# Passage au lowercase
clean_corpus = [w.lower() for w in clean_corpus]
```

<a id="two-d"></a>
### D. **Suppression des *stop-words***

- **Suppression des *stop-words***¬†: qui sont les mots tr√®s courants dans la langue √©tudi√©e ("et", "√†", "le"... en fran√ßais) et qui n'apportent pas r√©ellement de valeur informative pour la compr√©hension du sens du texte.

```python
from nltk.corpus import stopwords

# Stockage des stop-words fran√ßais
stop_words = stopwords.words('french')

# Ajout manuel de stop-words
other_stop_words = ['dont', 'ceci']
for w in other_stop_words:
    stop_words.append(w)

print(stop_words)
```

```python
# Suppression des stop-words du corpus
clean_corpus = [w for w in clean_corpus if not w in stop_words]
```

Il est d√©sormais int√©ressant de visualiser les mots les plus fr√©quents.

<a id="two-e"></a>
### E. Les mots les plus fr√©quents

```python
# Fr√©quence des mots
fdist1 = nltk.FreqDist(clean_corpus)
print(fdist1.most_common(50))
fdist1.plot(50)
```

![](images/wordfreq.png)

A ce niveau, les mots les plus fr√©quents le sont souvent car ils sont pr√©sents dans tous les textes. Ils restent largement informatifs mais sont peu discriminants dans le cas o√π on souhaiterait trouver ce qui distingue les textes les uns des autres.

- **Suppression des mots les plus fr√©quents**¬†: dans le cas o√π on souhaite distinguer des types de textes, il convient de supprimer les mots qu'ils ont en commun pour ne garder que ceux qui permettent de les distinguer.

```python
```

<a id="two-f"></a>
### F. La *lemmatisation*

- **La *lemmatisation*** : qui consiste √† repr√©senter les mots sous leur forme canonique. Les verbes conjugu√©s vont √™tre pass√©s √† l'infinitif, les noms au masculin singulier...

<a id="two-g"></a>
### G. Le *stemming*

- **Le *stemming*** :¬†qui permet de supprimer les pr√©fixes/suffixes connus pour ne garder que la racine (donc la partie la plus porteuse de sens) des mots.