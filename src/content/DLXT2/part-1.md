---
layout: post
title: üá´üá∑ Introduction aux R√©seaux de Neurones¬†‚Äì DLXT2 (Part. 1)
author: Quentin Monmousseau
tags: [Data Sc. & A.I.]
image: images/header-articles.png
date: 2019-05-11T23:46:37.121Z
draft: false
---

*Dans cet article, nous allons √©tudier le comportement d'un r√©seau de neurones classique puis nous construirons un mod√®le capable de pr√©dire le succ√®s de projets de crowdfunding gr√¢ce √† Tensorflow 2.0.*

---

### Sommaire  
**I. Le fonctionnement d'un r√©seau de neurones**  
‚Ä¢ Forward Propagation  
‚Ä¢ Back Propagation  

**II. Impl√©mentation avec Tensorflow 2.0**  
‚Ä¢ Forward Propagation  
‚Ä¢ Back Propagation  
‚Ä¢ Pr√©paration du jeu de donn√©es et entra√Ænement  

**III. Pistes d'am√©lioration du mod√®le**

---

## I. Le fonctionnement d'un r√©seau de neurones

Les r√©seaux de neurones sont le nerf de la guerre du Deep Learning. Th√©oris√©s depuis une cinquantaine d'ann√©es, ils sont longtemps rest√©s d√©ceptifs avant de revenir en force gr√¢ce √† la puissance de calcul des processeurs r√©cents. En d√©tectant des *patterns* parfois invisibles √† l'oeil nu, ils permettent une compr√©hension des donn√©es qui d√©passent parfois les meilleures *heuristiques*. Ainsi, dans le domaine de l'image processing par exemple, les r√©seaux de neurones se sont mis √† produire des r√©sultats sup√©rieurs √† des d√©tecteurs aux r√®gles √©tablies par des experts m√©tiers.

Pour comprendre comment tout cela fonctionne, commen√ßons √† l'√©chelle d'un neurone. Le processus se fait en deux grandes √©tapes, la <mark>**Forward Propagation**</mark> et la <mark>**Back Propagation**</mark>.

### Forward Propagation :  

![](images/neuralnet.png)
###### R√©seau de neurones √† layer unique

1. Le r√©seau de neurones va prendre les diff√©rentes features comme *inputs*.

2. Ces *inputs* sont multipli√©es par leur *poids* respectif. Ce *poids* est initialis√© selon certaines m√©thodes (comme celle de Xavier ou celle de He) et sera actualis√© durant l'entra√Ænement pour donner plus ou moins d'importance √† la feature.

3. On r√©alise alors une somme pond√©r√©e, c'est-√†-dire une somme de ces multiplications.

4. Cette somme est finalement donn√©e √† une *fonction d'activation* qui formate le r√©sultat et permet de produire la pr√©diction en *output*.

### Back Propagation :  
5. Cette pr√©diction va √™tre compar√©e √† la valeur attendue pour d√©terminer une mesure de l'erreur, on parle de fonction de *loss*. De plus, la contribution √† l'erreur de chaque neurone de la couche pr√©c√©dente va √™tre d√©termin√©e.

6. Une fonction *optimizer* (telle que la descente de gradient) va chercher √† minimiser la *loss* calcul√©e.

7. Le *gradient* √©tabli va permettre au r√©seau d'actualiser les *poids* initi√©s sur la couche pr√©c√©dente, en tenant compte de leur contribution √† l'erreur. Le processus est ensuite relancer x fois (avec x le nombre d'*epochs* fix√©s pour l'entra√Ænement).

Ce processus peut non seulement se r√©p√©ter mais √©galement √™tre multiple au sein m√™me du r√©seau. On  peut en effet ajouter plusieurs couches pour complexifier le mod√®le (ajouter de la non-lin√©arit√©) et le rendre plus puissant. Ces couches interm√©diaire sont appel√©es *hidden layers*. Plus on ajoute de couches, plus le r√©seau devient profond. C'est la raison pour laquelle on parle de Deep Learning.

![](images/deepneuralnet.png)
###### R√©seau de neurones multi-layers

---

## II. Impl√©mentation avec Tensorflow 2.0

Pour impl√©menter notre premier r√©seau de neurone, nous allons utiliser la nouvelle version de *Tensorflow*, j'ai nomm√© *Tensorflow 2.0*. La librairie a l'avantage d'absorber l'excellente API *Keras* qui facilite grandement la construction du mod√®le. Initialisons un mod√®le √† plusieurs *layers*.

```python
from tensorflow.keras.models import Sequential # pour cr√©er un mod√®le
from tensorflow.keras.layers import Dense # pour ajouter des couches

# Initialiser le mod√®le
classifier = keras.Sequential()
```

### Forward Propagation :  

Nous ajoutons les diff√©rents *layers* avec <code>.add(Dense())</code>. Il n'y a pas de r√®gle fixe quant au nombre de layers et de neurones √† l'int√©rieur, cela rel√®ve de l'intuition face √† la probl√©matique, de l'exp√©rimentation ou encore de certains calculs possibles. Ici nous en g√©n√©rons trois. Le premier est notre Input Layer, il contient 9 neurones pour les 9 features de notre mod√®le. Le second est un Hidden Layer de 3 neurones. Le dernier est l'Output Layer, il contient un seul neurone capable de pr√©dire la probabilit√© de succ√®s.

```python
classifier.keras.add(Dense(units=5, activation='relu', input_dim=9)) # input layer
classifier.add(Dense(units=3, activation='relu')) # hidden layer
classifier.add(Dense(units=1, activation='sigmoid')) # output layer
```

- <code>input_dim</code>: le nombre de features qui serviront d'inputs.
- <code>units</code>: le nombre de neurones (dimension de la couche).
- <code>activation</code>: la fonction d'activation souhait√©e.

### Back Propagation :  

Configurons maintenant la *back propagation* avec la fonction <code>.compile</code>. Celle-ci peut prendre un grand nombre d'arguments mais nous nous contentons ici des trois n√©cessaires pour faire fonctionner le r√©seau.

```python
classifier.compile(loss='mean_squared_error',
                   optimizer='sgd',
                   metrics=['accuracy'])
```

- <code>loss</code>: fonction d'erreur face au jeu d'entra√Ænement, qu'on va minimiser gr√¢ce √† l'optimizer.
- <code>optimizer</code>: m√©thode d'optimisation de la loss qui va permettre l'actualisation des poids. Ici nous utilisons la descente de gradient stochastique (*sgd* pour *stochastic gradient descent*).
- <code>metrics</code>: fonction finale de mesure de l'erreur, face au jeu de test.


### Pr√©paration du jeu de donn√©es et entra√Ænement

```python
# Import librairie(s)
import pandas as pd

# Ecriture du fichier .csv dans un dataframe pandas
df = pd.read_csv("../data/data.csv")

# Soit X les features de notre mod√®le...
X = df
X.drop(['state'], axis=1, inplace=True)

# ...et y la target √† pr√©dire
y = df['state']

```

```python
from sklearn.model_selection import train_test_split

# S√©paration des donn√©es en un jeu d'entra√Ænement et un jeu de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

On standardise les entr√©es pour que les diff√©rences d'√©chelle n'aient pas d'impact sur les sommes pond√©r√©es du mod√®le.

```python
from sklearn.preprocessing import StandardScaler

# Standardisation des entr√©es
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

Nous pouvons d√©sormais entra√Æner notre mod√®le. On fixe le nombre d'it√©rations √† 20 *epochs* et on place 20% des donn√©es dans un jeu de validation qui nous permettra d'√©valuer le mod√®le sur des donn√©es qu'il ne conna√Æt pas.

```python
# Entra√Ænement du mod√®le
history = model.fit(X_train, y_train, epochs=20, validation_split=0.2)
```

![](images/val.png)

On peut constater l'√©volution de nos mesures d'erreur sur les jeux d'entra√Ænement et de test. Cela permet notamment de monitorer l'entra√Ænement et de pr√©ciser le nombre d'*epochs* n√©cessaire √† l'entra√Ænement de notre mod√®le.

---

## III. Pistes d'am√©lioration du mod√®le

Les principaux facteurs qui d√©terminent la qualit√© de l'apprentissage sont les suivants :
- la qualit√© et la quantit√© des donn√©es utilis√©es,
- les features propos√©es au mod√®le,
- les poids initiaux,
- le nombre de neurones par couches, le nombre de couches,
- le choix de la fonction d'activation,
- le nombre d'epochs (monitorer l'apprentissage),
- faire attention au r√©sultat de l'*optimizer* car la fonction d'erreur est rarement convexe. Il existe donc des minima locaux qui emp√™chent les m√©thodes comme la descente de gradient de trouver le minimum global.